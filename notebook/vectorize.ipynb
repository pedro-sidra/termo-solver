{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import words\n",
    "import codecs\n",
    "from unidecode import unidecode\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import solver\n",
    "from solver.prob import *\n",
    "\n",
    "def printLetterArray(arr):\n",
    "    print('[', end=\"\")\n",
    "    for letter in arr:\n",
    "        print(letter, end=\" \")\n",
    "    print(']')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Words dataframe\n",
    "\n",
    "Contains all words in the official solutions. Also contains a vector representing each character as a alphabet-indexed number.\n",
    "\n",
    "### Columns:\n",
    "* **Word** : the word in characters\n",
    "* **0** : first letter`s index in the alphabet\n",
    "* **1** : second letter`s index in the alphabet\n",
    "* **2** : third letter`s index in the alphabet\n",
    "* **3** : fourth letter`s index in the alphabet\n",
    "* **4** : fifth letter`s index in the alphabet\n",
    "\n",
    "Alphabet index is calculated as:\n",
    "```python\n",
    "index = ord(c.lower()) - ord('a')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = wordVecDataframe()\n",
    "words "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coded words dataframe\n",
    "\n",
    "Contains the same words as `words`, but coded in a different way.\n",
    "\n",
    "Each row represents a word.\n",
    "\n",
    "Each column corresponds to an alphabet index. i.e. column 1 corresponds to 'b', column 2 corresponds to 'c' and so fourth\n",
    "\n",
    "Each value is a five-bit number representing the position(s) of the corresponding letter in the corresponding word.\n",
    "\n",
    "See example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "codes = wordCodes(words)\n",
    "print(f\"Codes vec: \\n{codes}\")\n",
    "print(f\"Shape: {codes.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example\n",
    "\n",
    "Change `i` to see different words as examples.\n",
    "\n",
    "Important variables:\n",
    "* words.word: the word in string format\n",
    "* v: the 5-dimension vector of alphabet indices representing the word\n",
    "* c: the 26-dimension vector of codes representing the same word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to see the index of any word you want:\n",
    "wanted = \"traca\"\n",
    "queried = words.query(\"`word`==@wanted\")\n",
    "queried"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = queried.index[0]\n",
    "\n",
    "w = words.iloc[i]\n",
    "v = words.iloc[i,1:].to_numpy()\n",
    "c = codes[i]\n",
    "\n",
    "print(\"Word:\")\n",
    "print(w.word)\n",
    "print(\"Letters vector:\")\n",
    "print(v)\n",
    "\n",
    "print(\"Coded vector:\")\n",
    "print(c)\n",
    "\n",
    "print(\"Decoded vector:\")\n",
    "print(decodeWord(c))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coded vector explanation\n",
    "\n",
    "Each letter contained in the word generates a non-zero entry in the coded vector:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{w.word=}\")\n",
    "\n",
    "# Legend\n",
    "printLetterArray(alphabet)\n",
    "\n",
    "# Non-zero entries in C\n",
    "print(1*(c!=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we code the positions in which each letter appears as a 5-bit number (little-endian)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get unique letters in the word\n",
    "print(\"Coded vector:\")\n",
    "print(c)\n",
    "idxs = setOfLetters(v)\n",
    "\n",
    "print(f\"{w.word=}\")\n",
    "for l in idxs:\n",
    "    print(\"---\")\n",
    "    print(f\"Coding for letter '{num2leter(l)}':\")\n",
    "    printLetterArray([letter+\" \" for letter in w.word])\n",
    "\n",
    "    places = 1*(v==l)\n",
    "    print(f\"{str(places).replace( ' ', '  ')} \\t=>\\t Place vector\")\n",
    "\n",
    "    bits = 2**np.arange(len(places))\n",
    "    code = np.sum(places*bits)\n",
    "    print(f\"[{str(bits)[2:-1]}] \\t=>\\t bits\")\n",
    "\n",
    "    print(f\"code=sum(places*bits) \\t=>\\t {code=}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "green = c&codes\n",
    "\n",
    "has_green =  np.sum(green,axis=1)!=0 \n",
    "\n",
    "greens = words.iloc[has_green].copy()\n",
    "greens[\"green\"] = [decodeWord(g) for g in green[has_green]]\n",
    "print(f\"{w.word=}\")\n",
    "print(\"Green Matches:\")\n",
    "greens=greens.drop(list(range(5)),axis=1)\n",
    "greens.head(n=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "green[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# NOTE: green==0 i'm not sure about.\n",
    "# Wordle does hint for yellow letters when there are repeated letters and a green letter was guessed\n",
    "# Letreco also does this\n",
    "# Termo... i`m not sure yet. TODO: Check.\n",
    "# yellow = ((~c)*(c!=0)*(green==0))&codes\n",
    "\n",
    "yellow = ((~codes)*(codes!=0))&c\n",
    "\n",
    "# cand = ( (~green)&c )\n",
    "# yellow = ( (~cand)*(cand!=0) )&codes\n",
    "# yellow = 1*(yellow!=0)\n",
    "yellow=yellow.astype(np.uint8)\n",
    "\n",
    "has_yellow =  np.sum(yellow,axis=1)!=0 \n",
    "\n",
    "yellows = words.iloc[has_yellow].copy()\n",
    "# yellows[\"yellow\"] = [decodeWord(g).replace(\"-\",\"\") for g in yellow[has_yellow]]\n",
    "yellows[\"yellow\"] = [decodeWord(g) for g in yellow[has_yellow]]\n",
    "yellows[\"code\"] = [g for g in yellow[has_yellow]]\n",
    "\n",
    "yellows=yellows.drop(list(range(5)),axis=1)\n",
    "\n",
    "print(f\"{w.word=}\")\n",
    "print(\"Yellow matches:\")\n",
    "# yellows.head(n=40)\n",
    "y = yellows.query(\"`word`=='pecar'\")\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y.code.to_numpy()[0]\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traca = c\n",
    "traca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pecar = codes[words.query(\"`word`=='pecar'\").index[0]]\n",
    "pecar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.vstack((np.arange(255),np.log2(np.arange(255)))).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gmpy\n",
    "popCountNp = np.vectorize(lambda x:gmpy.popcount(int(x)))\n",
    "# def popCount(x):\n",
    "#     return np.array([gmpy.popcount(int(e)) for e in x])\n",
    "\n",
    "# gmpy.popcount(20.0)\n",
    "print(\"Non-zero bitcount:\")\n",
    "print(popCountNp(y))\n",
    "print(popCountNp(pecar))\n",
    "print(\"===\")\n",
    "print(\"log:\")\n",
    "print(2**np.floor(np.log2(y)))\n",
    "print(y)\n",
    "print(\"===\")\n",
    "\n",
    "wrong = popCountNp(y) > popCountNp(pecar)\n",
    "corrections = wrong * (2**np.floor(np.log2(y)))\n",
    "corrections = corrections.astype(np.uint8)\n",
    "print(\"Yellow is wrong here:\")\n",
    "print(wrong)\n",
    "print(\"Subtract this to correct:\")\n",
    "print(corrections)\n",
    "print(\"===\")\n",
    "\n",
    "yn = (y & (~corrections))\n",
    "print(\"Corrected:\")\n",
    "print(yn)\n",
    "print(\"new Wrong-ness:\")\n",
    "print(popCountNp(yn) > popCountNp(pecar))\n",
    "print(\"New match:\")\n",
    "print(decodeWord(yn.astype(np.uint8)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"matches for {w.word}:\")\n",
    "matches = pd.merge(greens,yellows,how=\"outer\", on=\"word\").fillna(\" \")\n",
    "matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches.groupby([\"green\",\"yellow\"]).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy(labels, base=None):\n",
    "  value,counts = np.unique(labels, return_counts=True)\n",
    "  norm_counts = counts / counts.sum()\n",
    "  base = np.e if base is None else base\n",
    "  return -(norm_counts * np.log(norm_counts)/np.log(base)).sum()\n",
    "\n",
    "entropies = matches.groupby([\"green\",\"yellow\"]).apply(entropy)\n",
    "np.mean(entropies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_matches(c, codes):\n",
    "  green = c&codes\n",
    "  has_green =  np.sum(green,axis=1)!=0 \n",
    "  greens = words.iloc[has_green].copy()\n",
    "  greens[\"green\"] = green[has_green] #[decodeWord(g) for g in green[has_green]]\n",
    "\n",
    "  greens=greens.drop(list(range(5)),axis=1)\n",
    "\n",
    "  cand = ( (~green)&c )\n",
    "  yellow = ( (~cand)*(cand!=0) )&codes\n",
    "  yellow = 1*(yellow!=0)\n",
    "  yellow=yellow.astype(np.uint8)\n",
    "\n",
    "  has_yellow =  np.sum(yellow,axis=1)!=0 \n",
    "\n",
    "  yellows = words.iloc[has_yellow].copy()\n",
    "  yellows[\"yellow\"] = yellow[has_yellow] #[decodeWord(g).replace(\"-\",\"\") for g in yellow[has_yellow]]\n",
    "\n",
    "  yellows=yellows.drop(list(range(5)),axis=1)\n",
    "\n",
    "  return pd.merge(greens,yellows,how=\"outer\", on=\"word\").fillna(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "i=1\n",
    "w = words.iloc[i]\n",
    "v = words.iloc[i,1:].to_numpy()\n",
    "c = codes[i]\n",
    "\n",
    "\n",
    "matches = get_matches(c, codes)\n",
    "entropies = words[[\"word\"]].copy()\n",
    "\n",
    "for i in tqdm(entropies.index):\n",
    "    c = codes[i]\n",
    "    matches = get_matches(c, codes)\n",
    "    ent = matches.groupby([\"green\",\"yellow\"]).apply(entropy)\n",
    "    entropies[\"ent\"] = np.mean(ent)\n",
    "\n",
    "entropies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(entropy([1,2,3]))\n",
    "print(entropy([1,2,3,4]))\n",
    "print(entropy([1,2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try again..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "words ="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = wordVecDataframe()\n",
    "words "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sets = np.array([bagOfLettersVec(words.iloc[i,1:]) for i in range(len(words))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sets"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "843dce7d03e89fe4bf32be7f8c24be4adfeab22fe4e6b867a51e03289bbff473"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 (conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
