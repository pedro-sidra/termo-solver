{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import words\n",
    "import codecs\n",
    "from unidecode import unidecode\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import solver\n",
    "from solver.prob import *\n",
    "\n",
    "def printLetterArray(arr):\n",
    "    print('[', end=\"\")\n",
    "    for letter in arr:\n",
    "        print(letter, end=\" \")\n",
    "    print(']')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Words dataframe\n",
    "\n",
    "Contains all words in the official solutions. Also contains a vector representing each character as a alphabet-indexed number.\n",
    "\n",
    "### Columns:\n",
    "* **Word** : the word in characters\n",
    "* **0** : first letter`s index in the alphabet\n",
    "* **1** : second letter`s index in the alphabet\n",
    "* **2** : third letter`s index in the alphabet\n",
    "* **3** : fourth letter`s index in the alphabet\n",
    "* **4** : fifth letter`s index in the alphabet\n",
    "\n",
    "Alphabet index is calculated as:\n",
    "```python\n",
    "index = ord(c.lower()) - ord('a')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ababa</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ababe</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>abaci</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>abaca</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>abace</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12581</th>\n",
       "      <td>uteis</td>\n",
       "      <td>20</td>\n",
       "      <td>19</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12582</th>\n",
       "      <td>utero</td>\n",
       "      <td>20</td>\n",
       "      <td>19</td>\n",
       "      <td>4</td>\n",
       "      <td>17</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12583</th>\n",
       "      <td>uvico</td>\n",
       "      <td>20</td>\n",
       "      <td>21</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12584</th>\n",
       "      <td>uvido</td>\n",
       "      <td>20</td>\n",
       "      <td>21</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12585</th>\n",
       "      <td>uvula</td>\n",
       "      <td>20</td>\n",
       "      <td>21</td>\n",
       "      <td>20</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12586 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        word   0   1   2   3   4\n",
       "0      ababa   0   1   0   1   0\n",
       "1      ababe   0   1   0   1   4\n",
       "2      abaci   0   1   0   2   8\n",
       "3      abaca   0   1   0   2   0\n",
       "4      abace   0   1   0   2   4\n",
       "...      ...  ..  ..  ..  ..  ..\n",
       "12581  uteis  20  19   4   8  18\n",
       "12582  utero  20  19   4  17  14\n",
       "12583  uvico  20  21   8   2  14\n",
       "12584  uvido  20  21   8   3  14\n",
       "12585  uvula  20  21  20  11   0\n",
       "\n",
       "[12586 rows x 6 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = wordVecDataframe()\n",
    "words "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coded words dataframe\n",
    "\n",
    "Contains the same words as `words`, but coded in a different way.\n",
    "\n",
    "Each row represents a word.\n",
    "\n",
    "Each column corresponds to an alphabet index. i.e. column 1 corresponds to 'b', column 2 corresponds to 'c' and so fourth\n",
    "\n",
    "Each value is a five-bit number representing the position(s) of the corresponding letter in the corresponding word.\n",
    "\n",
    "See example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Codes vec: \n",
      "[[21 10  0 ...  0  0  0]\n",
      " [ 5 10  0 ...  0  0  0]\n",
      " [ 5  2  8 ...  0  0  0]\n",
      " ...\n",
      " [ 0  0  8 ...  0  0  0]\n",
      " [ 0  0  0 ...  0  0  0]\n",
      " [16  0  0 ...  0  0  0]]\n",
      "Shape: (12586, 26)\n"
     ]
    }
   ],
   "source": [
    "codes = wordCodes(words)\n",
    "print(f\"Codes vec: \\n{codes}\")\n",
    "print(f\"Shape: {codes.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example\n",
    "\n",
    "Change `i` to see different words as examples.\n",
    "\n",
    "Important variables:\n",
    "* words.word: the word in string format\n",
    "* v: the 5-dimension vector of alphabet indices representing the word\n",
    "* c: the 26-dimension vector of codes representing the same word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11187</th>\n",
       "      <td>traca</td>\n",
       "      <td>19</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        word   0   1  2  3  4\n",
       "11187  traca  19  17  0  2  0"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to see the index of any word you want:\n",
    "wanted = \"traca\"\n",
    "queried = words.query(\"`word`==@wanted\")\n",
    "queried"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word:\n",
      "traca\n",
      "Letters vector:\n",
      "[19 17 0 2 0]\n",
      "Coded vector:\n",
      "[20  0  8  0  0  0  0  0  0  0  0  0  0  0  0  0  0  2  0  1  0  0  0  0\n",
      "  0  0]\n",
      "Decoded vector:\n",
      "traca\n"
     ]
    }
   ],
   "source": [
    "i = queried.index[0]\n",
    "\n",
    "w = words.iloc[i]\n",
    "v = words.iloc[i,1:].to_numpy()\n",
    "c = codes[i]\n",
    "\n",
    "print(\"Word:\")\n",
    "print(w.word)\n",
    "print(\"Letters vector:\")\n",
    "print(v)\n",
    "\n",
    "print(\"Coded vector:\")\n",
    "print(c)\n",
    "\n",
    "print(\"Decoded vector:\")\n",
    "print(decodeWord(c))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coded vector explanation\n",
    "\n",
    "Each letter contained in the word generates a non-zero entry in the coded vector:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w.word='traca'\n",
      "[a b c d e f g h i j k l m n o p q r s t u v w x y z ]\n",
      "[1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(f\"{w.word=}\")\n",
    "\n",
    "# Legend\n",
    "printLetterArray(alphabet)\n",
    "\n",
    "# Non-zero entries in C\n",
    "print(1*(c!=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we code the positions in which each letter appears as a 5-bit number (little-endian)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coded vector:\n",
      "[20  0  8  0  0  0  0  0  0  0  0  0  0  0  0  0  0  2  0  1  0  0  0  0\n",
      "  0  0]\n",
      "w.word='traca'\n",
      "---\n",
      "Coding for letter 'a':\n",
      "[t  r  a  c  a  ]\n",
      "[0  0  1  0  1] \t=>\t Place vector\n",
      "[1  2  4  8 16] \t=>\t bits\n",
      "code=sum(places*bits) \t=>\t code=20\n",
      "---\n",
      "Coding for letter 'r':\n",
      "[t  r  a  c  a  ]\n",
      "[0  1  0  0  0] \t=>\t Place vector\n",
      "[1  2  4  8 16] \t=>\t bits\n",
      "code=sum(places*bits) \t=>\t code=2\n",
      "---\n",
      "Coding for letter 'c':\n",
      "[t  r  a  c  a  ]\n",
      "[0  0  0  1  0] \t=>\t Place vector\n",
      "[1  2  4  8 16] \t=>\t bits\n",
      "code=sum(places*bits) \t=>\t code=8\n",
      "---\n",
      "Coding for letter 't':\n",
      "[t  r  a  c  a  ]\n",
      "[1  0  0  0  0] \t=>\t Place vector\n",
      "[1  2  4  8 16] \t=>\t bits\n",
      "code=sum(places*bits) \t=>\t code=1\n"
     ]
    }
   ],
   "source": [
    "# Get unique letters in the word\n",
    "print(\"Coded vector:\")\n",
    "print(c)\n",
    "idxs = setOfLetters(v)\n",
    "\n",
    "print(f\"{w.word=}\")\n",
    "for l in idxs:\n",
    "    print(\"---\")\n",
    "    print(f\"Coding for letter '{num2leter(l)}':\")\n",
    "    printLetterArray([letter+\" \" for letter in w.word])\n",
    "\n",
    "    places = 1*(v==l)\n",
    "    print(f\"{str(places).replace( ' ', '  ')} \\t=>\\t Place vector\")\n",
    "\n",
    "    bits = 2**np.arange(len(places))\n",
    "    code = np.sum(places*bits)\n",
    "    print(f\"[{str(bits)[2:-1]}] \\t=>\\t bits\")\n",
    "\n",
    "    print(f\"code=sum(places*bits) \\t=>\\t {code=}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w.word='traca'\n",
      "Green Matches:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>green</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ababa</td>\n",
       "      <td>--a-a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ababe</td>\n",
       "      <td>--a--</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>abaci</td>\n",
       "      <td>--ac-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>abaca</td>\n",
       "      <td>--aca</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>abace</td>\n",
       "      <td>--ac-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>abada</td>\n",
       "      <td>--a-a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>abade</td>\n",
       "      <td>--a--</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>abado</td>\n",
       "      <td>--a--</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>abafa</td>\n",
       "      <td>--a-a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>abafe</td>\n",
       "      <td>--a--</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>abafo</td>\n",
       "      <td>--a--</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>abais</td>\n",
       "      <td>--a--</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>abaio</td>\n",
       "      <td>--a--</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>abaju</td>\n",
       "      <td>--a--</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>abaja</td>\n",
       "      <td>--a-a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>abala</td>\n",
       "      <td>--a-a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>abale</td>\n",
       "      <td>--a--</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>abalo</td>\n",
       "      <td>--a--</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>abama</td>\n",
       "      <td>--a-a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>abana</td>\n",
       "      <td>--a-a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>abane</td>\n",
       "      <td>--a--</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>abano</td>\n",
       "      <td>--a--</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>abapo</td>\n",
       "      <td>--a--</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>abara</td>\n",
       "      <td>--a-a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>abare</td>\n",
       "      <td>--a--</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>abaso</td>\n",
       "      <td>--a--</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>abata</td>\n",
       "      <td>--a-a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>abate</td>\n",
       "      <td>--a--</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>abati</td>\n",
       "      <td>--a--</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>abato</td>\n",
       "      <td>--a--</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     word  green\n",
       "0   ababa  --a-a\n",
       "1   ababe  --a--\n",
       "2   abaci  --ac-\n",
       "3   abaca  --aca\n",
       "4   abace  --ac-\n",
       "5   abada  --a-a\n",
       "6   abade  --a--\n",
       "7   abado  --a--\n",
       "8   abafa  --a-a\n",
       "9   abafe  --a--\n",
       "10  abafo  --a--\n",
       "11  abais  --a--\n",
       "12  abaio  --a--\n",
       "13  abaju  --a--\n",
       "14  abaja  --a-a\n",
       "15  abala  --a-a\n",
       "16  abale  --a--\n",
       "17  abalo  --a--\n",
       "18  abama  --a-a\n",
       "19  abana  --a-a\n",
       "20  abane  --a--\n",
       "21  abano  --a--\n",
       "22  abapo  --a--\n",
       "23  abara  --a-a\n",
       "24  abare  --a--\n",
       "25  abaso  --a--\n",
       "26  abata  --a-a\n",
       "27  abate  --a--\n",
       "28  abati  --a--\n",
       "29  abato  --a--"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "green = c&codes\n",
    "\n",
    "has_green =  np.sum(green,axis=1)!=0 \n",
    "\n",
    "greens = words.iloc[has_green].copy()\n",
    "greens[\"green\"] = [decodeWord(g) for g in green[has_green]]\n",
    "print(f\"{w.word=}\")\n",
    "print(\"Green Matches:\")\n",
    "greens=greens.drop(list(range(5)),axis=1)\n",
    "greens.head(n=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([20,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0], dtype=uint8)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "green[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_19087/151715075.py:16: RuntimeWarning: divide by zero encountered in log2\n",
      "  corrections = wrong * (2**np.floor(np.log2(yellow)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w.word='traca'\n",
      "Yellow matches:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>yellow</th>\n",
       "      <th>code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8420</th>\n",
       "      <td>pecar</td>\n",
       "      <td>-rac-</td>\n",
       "      <td>[4, 0, 8, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       word yellow                                               code\n",
       "8420  pecar  -rac-  [4, 0, 8, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ..."
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gmpy\n",
    "popCountNp = np.vectorize(lambda x:gmpy.popcount(int(x)))\n",
    "\n",
    "# NOTE: green==0 i'm not sure about.\n",
    "# Wordle does hint for yellow letters when there are repeated letters and a green letter was guessed\n",
    "# Letreco also does this\n",
    "# Termo... i`m not sure yet. TODO: Check.\n",
    "# yellow = ((~c)*(c!=0)*(green==0))&codes\n",
    "\n",
    "yellow = ((~codes)*(codes!=0))&c\n",
    "\n",
    "# print(popCountNp(yellow))\n",
    "# print(popCountNp(codes))\n",
    "\n",
    "wrong = popCountNp(yellow) > popCountNp(codes)\n",
    "corrections = wrong * (2**np.floor(np.log2(yellow)))\n",
    "corrections = corrections.astype(np.uint8)\n",
    "\n",
    "newYellow = (yellow & (~corrections))\n",
    "# print(\"Corrected:\")\n",
    "# print(yn)\n",
    "# print(\"new Wrong-ness:\")\n",
    "# print(popCountNp(yn) > popCountNp(pecar))\n",
    "# print(\"New match:\")\n",
    "# print(decodeWord(yn.astype(np.uint8)))\n",
    "\n",
    "\n",
    "# cand = ( (~green)&c )\n",
    "# yellow = ( (~cand)*(cand!=0) )&codes\n",
    "# yellow = 1*(yellow!=0)\n",
    "newYellow=newYellow.astype(np.uint8)\n",
    "yellow=yellow.astype(np.uint8)\n",
    "\n",
    "yellow=newYellow\n",
    "\n",
    "has_yellow =  np.sum(yellow,axis=1)!=0 \n",
    "\n",
    "yellows = words.iloc[has_yellow].copy()\n",
    "# yellows[\"yellow\"] = [decodeWord(g).replace(\"-\",\"\") for g in yellow[has_yellow]]\n",
    "yellows[\"yellow\"] = [decodeWord(g) for g in yellow[has_yellow]]\n",
    "yellows[\"code\"] = [g for g in yellow[has_yellow]]\n",
    "\n",
    "yellows=yellows.drop(list(range(5)),axis=1)\n",
    "\n",
    "print(f\"{w.word=}\")\n",
    "print(\"Yellow matches:\")\n",
    "# yellows.head(n=40)\n",
    "y = yellows.query(\"`word`=='pecar'\")\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y.code.to_numpy()[0]\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traca = c\n",
    "traca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pecar = codes[words.query(\"`word`=='pecar'\").index[0]]\n",
    "pecar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.vstack((np.arange(255),np.log2(np.arange(255)))).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def popCount(x):\n",
    "#     return np.array([gmpy.popcount(int(e)) for e in x])\n",
    "\n",
    "# gmpy.popcount(20.0)\n",
    "print(\"Non-zero bitcount:\")\n",
    "print(popCountNp(y))\n",
    "print(popCountNp(pecar))\n",
    "print(\"===\")\n",
    "print(\"log:\")\n",
    "print(2**np.floor(np.log2(y)))\n",
    "print(y)\n",
    "print(\"===\")\n",
    "\n",
    "wrong = popCountNp(y) > popCountNp(pecar)\n",
    "corrections = wrong * (2**np.floor(np.log2(y)))\n",
    "corrections = corrections.astype(np.uint8)\n",
    "print(\"Yellow is wrong here:\")\n",
    "print(wrong)\n",
    "print(\"Subtract this to correct:\")\n",
    "print(corrections)\n",
    "print(\"===\")\n",
    "\n",
    "yn = (y & (~corrections))\n",
    "print(\"Corrected:\")\n",
    "print(yn)\n",
    "print(\"new Wrong-ness:\")\n",
    "print(popCountNp(yn) > popCountNp(pecar))\n",
    "print(\"New match:\")\n",
    "print(decodeWord(yn.astype(np.uint8)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"matches for {w.word}:\")\n",
    "matches = pd.merge(greens,yellows,how=\"outer\", on=\"word\").fillna(\" \")\n",
    "matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches.groupby([\"green\",\"yellow\"]).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy(labels, base=None):\n",
    "  value,counts = np.unique(labels, return_counts=True)\n",
    "  norm_counts = counts / counts.sum()\n",
    "  base = np.e if base is None else base\n",
    "  return -(norm_counts * np.log(norm_counts)/np.log(base)).sum()\n",
    "\n",
    "entropies = matches.groupby([\"green\",\"yellow\"]).apply(entropy)\n",
    "np.mean(entropies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_matches(c, codes):\n",
    "  green = c&codes\n",
    "  has_green =  np.sum(green,axis=1)!=0 \n",
    "  greens = words.iloc[has_green].copy()\n",
    "  greens[\"green\"] = green[has_green] #[decodeWord(g) for g in green[has_green]]\n",
    "\n",
    "  greens=greens.drop(list(range(5)),axis=1)\n",
    "\n",
    "  cand = ( (~green)&c )\n",
    "  yellow = ( (~cand)*(cand!=0) )&codes\n",
    "  yellow = 1*(yellow!=0)\n",
    "  yellow=yellow.astype(np.uint8)\n",
    "\n",
    "  has_yellow =  np.sum(yellow,axis=1)!=0 \n",
    "\n",
    "  yellows = words.iloc[has_yellow].copy()\n",
    "  yellows[\"yellow\"] = yellow[has_yellow] #[decodeWord(g).replace(\"-\",\"\") for g in yellow[has_yellow]]\n",
    "\n",
    "  yellows=yellows.drop(list(range(5)),axis=1)\n",
    "\n",
    "  return pd.merge(greens,yellows,how=\"outer\", on=\"word\").fillna(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "i=1\n",
    "w = words.iloc[i]\n",
    "v = words.iloc[i,1:].to_numpy()\n",
    "c = codes[i]\n",
    "\n",
    "\n",
    "matches = get_matches(c, codes)\n",
    "entropies = words[[\"word\"]].copy()\n",
    "\n",
    "for i in tqdm(entropies.index):\n",
    "    c = codes[i]\n",
    "    matches = get_matches(c, codes)\n",
    "    ent = matches.groupby([\"green\",\"yellow\"]).apply(entropy)\n",
    "    entropies[\"ent\"] = np.mean(ent)\n",
    "\n",
    "entropies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(entropy([1,2,3]))\n",
    "print(entropy([1,2,3,4]))\n",
    "print(entropy([1,2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try again..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "words ="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = wordVecDataframe()\n",
    "words "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sets = np.array([bagOfLettersVec(words.iloc[i,1:]) for i in range(len(words))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sets"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "843dce7d03e89fe4bf32be7f8c24be4adfeab22fe4e6b867a51e03289bbff473"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 (conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
