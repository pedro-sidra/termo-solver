{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import words\n",
    "import codecs\n",
    "from unidecode import unidecode\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import solver\n",
    "from solver.prob import *\n",
    "\n",
    "def printLetterArray(arr):\n",
    "    print('[', end=\"\")\n",
    "    for letter in arr:\n",
    "        print(letter, end=\" \")\n",
    "    print(']')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Words dataframe\n",
    "\n",
    "Contains all words in the official solutions. Also contains a vector representing each character as a alphabet-indexed number.\n",
    "\n",
    "### Columns:\n",
    "* **Word** : the word in characters\n",
    "* **0** : first letter`s index in the alphabet\n",
    "* **1** : second letter`s index in the alphabet\n",
    "* **2** : third letter`s index in the alphabet\n",
    "* **3** : fourth letter`s index in the alphabet\n",
    "* **4** : fifth letter`s index in the alphabet\n",
    "\n",
    "Alphabet index is calculated as:\n",
    "```python\n",
    "index = ord(c.lower()) - ord('a')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = wordVecDataframe(language=\"pt\")\n",
    "words "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coded words dataframe\n",
    "\n",
    "Contains the same words as `words`, but coded in a different way.\n",
    "\n",
    "Each row represents a word.\n",
    "\n",
    "Each column corresponds to an alphabet index. i.e. column 1 corresponds to 'b', column 2 corresponds to 'c' and so fourth\n",
    "\n",
    "Each value is a five-bit number representing the position(s) of the corresponding letter in the corresponding word.\n",
    "\n",
    "See example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "codes= wordCodes(words.iloc[:,1:].to_numpy().astype(int))\n",
    "print(f\"Codes vec: \\n{codes}\")\n",
    "print(f\"Shape: {codes.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example\n",
    "\n",
    "Change `i` to see different words as examples.\n",
    "\n",
    "Important variables:\n",
    "* words.word: the word in string format\n",
    "* v: the 5-dimension vector of alphabet indices representing the word\n",
    "* c: the 26-dimension vector of codes representing the same word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to see the index of any word you want:\n",
    "wanted = \"traca\"\n",
    "queried = words.query(\"`word`==@wanted\")\n",
    "queried"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = queried.index[0]\n",
    "\n",
    "w = words.iloc[i]\n",
    "v = words.iloc[i,1:].to_numpy()\n",
    "c = codes[i]\n",
    "\n",
    "print(\"Word:\")\n",
    "print(w.word)\n",
    "print(\"Letters vector:\")\n",
    "print(v)\n",
    "\n",
    "print(\"Coded vector:\")\n",
    "print(c)\n",
    "\n",
    "print(\"Decoded vector:\")\n",
    "print(decodeWord(c))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coded vector explanation\n",
    "\n",
    "Each letter contained in the word generates a non-zero entry in the coded vector:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{w.word=}\")\n",
    "\n",
    "# Legend\n",
    "printLetterArray(alphabet)\n",
    "\n",
    "# Non-zero entries in C\n",
    "print(1*(c!=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we code the positions in which each letter appears as a 5-bit number (little-endian)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get unique letters in the word\n",
    "print(\"Coded vector:\")\n",
    "print(c)\n",
    "idxs = setOfLetters(v)\n",
    "\n",
    "print(f\"{w.word=}\")\n",
    "for l in idxs:\n",
    "    print(\"---\")\n",
    "    print(f\"Coding for letter '{num2leter(l)}':\")\n",
    "    printLetterArray([letter+\" \" for letter in w.word])\n",
    "\n",
    "    places = 1*(v==l)\n",
    "    print(f\"{str(places).replace( ' ', '  ')} \\t=>\\t Place vector\")\n",
    "\n",
    "    bits = 2**np.arange(len(places))\n",
    "    code = np.sum(places*bits)\n",
    "    print(f\"[{str(bits)[2:-1]}] \\t=>\\t bits\")\n",
    "\n",
    "    print(f\"code=sum(places*bits) \\t=>\\t {code=}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches = words.copy().drop(list(range(5)),axis=1)\n",
    "matches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorized functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decodeToBits(c):\n",
    "    return np.asarray([np.unpackbits(i, bitorder=\"little\")[:5] for i in c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_code(arr):\n",
    "    return np.sum(_bitValues*arr, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_bitValues = 2**np.arange(5)\n",
    "def get_green_matches(codeword, codeset):\n",
    "    greens = codeword&codeset\n",
    "    return greens\n",
    "\n",
    "def codify_matches(codedMatches):\n",
    "    n = len(codedMatches)\n",
    "    bits = (np.unpackbits(codedMatches.flatten(),bitorder=\"little\")\n",
    "        .reshape( (n, 26, 8) )\n",
    "        [:,:,:5]\n",
    "        )\n",
    "    matches =  np.sum(bits, axis=1)\n",
    "    # return [str(m) for m in matches]\n",
    "    # return matches\n",
    "    return match_code(matches)\n",
    "\n",
    "    \n",
    "# green = get_green_matches(c,codes)\n",
    "greens = get_green_matches(c,codes)\n",
    "matches[\"green\"] = codify_matches(greens)\n",
    "matches[\"greenP\"] = [decodeWord(g) for g in get_green_matches(c,codes)]\n",
    "print(f\"{w.word=}\")\n",
    "print(\"Green Matches:\")\n",
    "matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gmpy2\n",
    "popCountNp = np.vectorize(lambda x:gmpy2.popcount(int(x)), otypes=[np.uint32])\n",
    "# popCountNp= lambda x: [gmpy2.popcount(n) for n in x]\n",
    "\n",
    "def log2impl(x):\n",
    "    output = np.zeros_like(x)\n",
    "    vals = 2**np.arange(8)\n",
    "    itr = list(enumerate(vals))\n",
    "    for i, num in (itr):\n",
    "        output[ x - num >= 0 ] = i\n",
    "    \n",
    "    return output\n",
    "\n",
    "def bit_count(arr):\n",
    "     # Make the values type-agnostic (as long as it's integers)\n",
    "     t = arr.dtype.type\n",
    "     mask = t(-1)\n",
    "     s55 = t(0x5555555555555555 & mask)  # Add more digits for 128bit support\n",
    "     s33 = t(0x3333333333333333 & mask)\n",
    "     s0F = t(0x0F0F0F0F0F0F0F0F & mask)\n",
    "     s01 = t(0x0101010101010101 & mask)\n",
    "\n",
    "     arr = arr - ((arr >> 1) & s55)\n",
    "     arr = (arr & s33) + ((arr >> 2) & s33)\n",
    "     arr = (arr + (arr >> 4)) & s0F\n",
    "     return (arr * s01) >> (8 * (arr.itemsize - 1))\n",
    "\n",
    "# def bit_count(arr):\n",
    "#     return np.sum(np.unpackbits(arr.astype(np.uint8)).reshape(*arr.shape,8),axis=-1)\n",
    "def get_yellow_matches(codeword, codeset, greens):\n",
    "    # ~codeset: has a 5-bit mask for each letter, \n",
    "    #           with 1s where that letter is not located on the word\n",
    "    #           (consequently the 5-bit mask=11111 for letters not in the word)\n",
    "    # ~codeset * codeset!=0: eliminates the erroneous 5-bit masks for letters that are not in the word\n",
    "    # yellow: has 1s where the letter in the codeword matches a letter in the codeset,\n",
    "    #         but not in the same position\n",
    "    # nongreen = codeset & ((~greens)*(greens!=0))\n",
    "    # codeset = codeset \n",
    "    nongreen = codeset & ~greens\n",
    "    yellow = (((~codeset)*(codeset!=0)))&codeword\n",
    "    yellow = yellow & ~greens\n",
    "\n",
    "    # Yellow is not as expected\n",
    "    # Example:\n",
    "    #    codeword   = traca\n",
    "    #    codeset[i] = pavos\n",
    "    #    yellow =     --y-y\n",
    "    #should be  =     --y--\n",
    "    # Because the count of letters should be considered. \n",
    "    # E.g. --y-y implies there are two 'a's in the match\n",
    "\n",
    "    # Correct for different count of matches\n",
    "\n",
    "    # Popcount = number of nonzero bits in each letter\n",
    "    # if there are more nonzero bits in the match than in the original word,\n",
    "    # correct it\n",
    "    wrong = bit_count(yellow.astype(np.uint8)) > bit_count(nongreen.astype(np.uint8))\n",
    "    while np.any(wrong):\n",
    "        # highestbits = 1<<log2impl(yellow.astype(int))\n",
    "        highestbits = 2**np.floor(np.log2(yellow))\n",
    "        # highestbits[yellow==0] = 0\n",
    "\n",
    "        corrections = wrong * highestbits\n",
    "        corrections = corrections.astype(np.uint8)\n",
    "\n",
    "        yellow = (yellow & (~corrections))\n",
    "        # Recompute the `wrong` mask (corrections only clears one bit, there might be more)\n",
    "        wrong = bit_count(yellow.astype(np.uint8)) > bit_count(nongreen.astype(np.uint8))\n",
    "        yellow=yellow.astype(np.uint8)\n",
    "\n",
    "    return yellow\n",
    "    # return np.sum(_bitValues*yellow, axis=1)\n",
    "\n",
    "\n",
    "yellows = get_yellow_matches(c, codes, greens)\n",
    "matches[\"yellow\"] = codify_matches(yellows)\n",
    "matches[\"yellowP\"] = [decodeWord(y) for y in yellows]\n",
    "\n",
    "print(f\"{w.word=}\")\n",
    "print(\"Yellow matches:\")\n",
    "matches[[\"word\",\"yellow\",\"yellowP\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(w.word)\n",
    "matches[[ \"word\", \"greenP\",\"yellowP\" ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(w.word)\n",
    "matches.query(\"word=='crane'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"matches for {w.word}:\")\n",
    "show= matches.loc[:,[\"word\", \"greenP\",\"yellowP\"]]\n",
    "show.query(\"yellowP!='-----'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = matches.groupby([\"green\",\"yellow\"]).count()[\"word\"]\n",
    "groups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying vectorized functions\n",
    "\n",
    "You can use a new axis to do the full NxNx26 match codes, but likely you`ll run out of memory (~32GB).\n",
    "\n",
    "So here we do the vectorized ops one letter at a time. Then coalesce all results into a NxNx5 'binary matches' vector, one for greens and one for yellow.\n",
    "\n",
    "Likely you can do this 2 or 3 letters at a time without running out of memory, but my machine only has 6GB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Green matches\n",
    "\n",
    "Green matches for ALL combinations of words. Rows = query, columns = matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n, let = words.iloc[:,1:].shape\n",
    "\n",
    "# Full matrix\n",
    "greens = np.zeros((n,n), dtype=np.uint8)\n",
    "\n",
    "# For each letter\n",
    "for i in tqdm.tqdm(range(26)):\n",
    "    # Check matches between all words and all other words for that letter\n",
    "    out = get_green_matches(codes[:,np.newaxis,i:i+1],codes[...,i:i+1])\n",
    "\n",
    "    # Set bits in `greens` in positions that have matches\n",
    "    greens +=  out[...,0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Yellow matches\n",
    "\n",
    "Yellow matches for ALL combinations of words. Rows = query, columns = matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n, let = words.iloc[:,1:].shape\n",
    "\n",
    "yellows = np.zeros((n,n), dtype=np.uint8)\n",
    "for i in tqdm.tqdm(range(26)):\n",
    "    out = get_yellow_matches(codes[:,np.newaxis,i:i+1],codes[...,i:i+1], greens[...,i:i+1])\n",
    "    yellows[...] += out[...,0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "n, let = words.iloc[:,1:].shape\n",
    "\n",
    "# Full matrix\n",
    "greens = np.zeros((n,n), dtype=np.uint8)\n",
    "yellows = np.zeros((n,n), dtype=np.uint8)\n",
    "\n",
    "# For each letter\n",
    "for i in tqdm.tqdm(range(26)):\n",
    "    # Check matches between all words and all other words for that letter\n",
    "    partial_greens = get_green_matches(codes[:,np.newaxis,i:i+1],codes[...,i:i+1])\n",
    "    # Set bits in `greens` in positions that have matches\n",
    "    greens +=  partial_greens[...,0]\n",
    "\n",
    "    partial_yellows = get_yellow_matches(codes[:,np.newaxis,i:i+1],codes[...,i:i+1], partial_greens)\n",
    "    yellows[...] += partial_yellows[...,0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yellows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(yellows.shape)\n",
    "print(greens.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = queried.index[0]\n",
    "print(np.all(yellows[i]==matches.yellow))\n",
    "print(np.all(greens[i]==matches.green))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "codes[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yellowWrongs = np.where(yellows[i]!=matches.yellow)\n",
    "dfYWrong = matches.iloc[yellowWrongs].copy()\n",
    "\n",
    "dfYWrong[\"yellowVec\"] = yellows[i][yellowWrongs]\n",
    "\n",
    "print(f\"{w.word=}\")\n",
    "dfYWrong[[\"yellow\",\"yellowVec\"]] = dfYWrong[[\"yellow\",\"yellowVec\"]].apply(lambda x: x.apply(lambda y: bin(int(y)) ))\n",
    "dfYWrong[[\"word\",\"yellow\",\"yellowVec\",\"greenP\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"matches\"\n",
    "np.savez(file, greens=greens, yellows=yellows, words=words.iloc[:,0].to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "read = np.load(file+\".npz\", allow_pickle=True)\n",
    "print(np.all(read[\"greens\"] == greens))\n",
    "print(np.all(read[\"yellows\"] =="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " yellows))\n",
    "read[\"words\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "843dce7d03e89fe4bf32be7f8c24be4adfeab22fe4e6b867a51e03289bbff473"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 (conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
